 ---
title: "Doubly Robust Augmented Inverse Probability Weighted Estimator"
output: html_document
---
In this section, we introduce a doubly-robust method for estimating optimal treatment regimes, called Augmented Inverse Probability Weighted Estimator (AIPWE).This estimator incorporate both [inverse probability weighted estimator](potentially put the server link to it) and [outcome regression estimator](Outcome_Regression.html). Both outcome regression estimator and the inverse probability weighted estimator obtain consistency only if models involved are correctly specified. Augmenting the inverse probability weighted estimator with the outcome regression estimator, Augment Inverse Probability Weighted Estimator alleviate the possible confounding concern and increase precision. It is a consistent estimator as long as either the outcome regression model or the propensity score model is correctly specified, which introduces the doubly-robustness property.

We quickly review the same setting of the outcome regression method described in last section. In a single-stage clinical trial or observational study, we have $n$ subjects sampled from the patient population of interests. The treatment $A$ has options $\{ 0, 1\}$ (or $\{ -1, 1\}$).The patient characteristics vector collected before the treatment assignment is denoted by $X$, where $X\in \mathbf{R}^p$. $Y$ denotes the observed outcome of interest, and is preferred to be higher value. Then, the observed data, written as $(Y_i, A_i, X_i)$, $i = 1, \cdots, n$, are independent and identically distributed across i. The two potential outcomes are denoted by $\{ Y^*(0), Y^*(1)\}$. The treatment regime is a function $g$ that maps the domain of $X$ to $\{0, 1\}$ (or $\{-1, 1\}$). We define the potential outcome under an arbitrary regime $g$ as $Y^*(g) = Y^*(1) g(X) + Y^*(0)\left\{ 1 - g(X) \right\}$. Under the three necessary assumptions mentioned before [ADD LINKS TO THE ASSUMPTIONS HERE], we have that $Q(X,a) \triangleq E\left(Y \mid X=X, A=a\right) = E\{ Y^{*}(a) \mid X=X\}$ , for $a \in \{0, 1 \}$ ( or $\{-1, 1 \}$). Therefore, the optimal regime is defined as $g^{opt}(X) = \mathbf{I}\{Q(X, 1) > Q(X, 0) \},$ where treatment 0 is chosen if both treatment options give the same outcome value. As the Q-functions are usually unknown, we can posit a regression model for $Q(X,a) = E(Y \mid X, a)$ with finite-dimensinal parameter $\beta$. The class of regimes defined by this modeling is denoted by $\mathcal{G}_{\beta} = \{g_{\beta}: g_{\beta} \triangleq g(X, \beta) = \mathbf{I}\{Q(X, 1, \beta) > Q(X, 0, \beta), \beta \in \mathbf{R}^p\}$. If the model is correctly specified, then we have $Q(X, A) = Q(X, A; \beta_0)$, and the  true optimal regime is $g^{opt}(X, \beta_0) = \mathbf{I} \{ Q(X, 1; \beta_0) > Q(X, 0; \beta_0)\}$. We estimate the parameter $\beta$ with some proper method, and denote the obtained estimator by $\widehat{\beta}$. Consequently, we have an estimator of the optimal regime based on outcome regression method as $\widehat{g}^{opt}(X, \widehat{\beta}) = \mathbf{I}\{ Q(X, 1; \widehat{\beta}) > Q(X, 0; \widehat{\beta}) \}$. Moreover, an estimator of the overall mean outcome under the optimal regime, $E\left\{ Y^{*}\left( g^{opt}\right) \right\}$, named outcome regression estimator, is formalized as

$$n^{-1}\sum_{i=1}^{n} \underset{a \in \{0, 1\}}{\text{max}} Q( X_i, a; \widehat{\beta}).$$


Critically, $\widehat{g}^{opt}(X, \widehat{\beta})$ is a trustworthy estimator for the true optimal regime, only if the model $Q(X, A; \beta)$ is correctly specified. However, if the model is misspecified, the treatment assignment based the misspecified estimator will not lead to the truth, $E\{Y^*(g^{opt})\}$. However, misspecification in the regression model of $Q(X, a, \eta)$ may lead inconsistent estimators of the optimal regime and exhibit poor performance. The true optimal regime $g^{\text{opt}}$ may not in the class of regime $\mathcal{G}_{\eta}$.

A remedy to this issue is to identify an estimator for $E\{ Y^*(g_{\eta}) \}$ and find $\widehat{\eta}^{opt}$ by maximizing it directly over $\eta$. Again, $g_{\eta}$ denotes an arbitrary function in the class of regime under consideration indexed by parameter $\eta$, $\mathcal{G}_{\eta}$. To find the maximizer $\eta$, we may construct an estimator for $E\{ Y^*(g_{\eta}) \}$ from the missing data perspective, named inverse probability weighted estimator. Here we omit the details of how to construct this estimator and present it directly. The inverse probability weighted estimator (IPWE) is given by
$$\text{IWPE}(\eta) = n^{-1} \sum_{i=1}^n\frac{C_{\eta,i}Y_i}{\pi_{c}(X_i;\eta, \widehat{\gamma})},$$
where $C_{\eta} = A g(X, \eta) + (1 -A) \left\{ 1 - g(X, \eta)\right\}$ and $\pi_c(X;\eta, \widehat{\gamma}) = \pi(X;\widehat{\gamma}) g(X, \eta) + \{1 - \pi(X;\widehat{\gamma})\}\{1- g(X, \eta)\}$. We let $\pi(X) \triangleq  Pr(A =1 \mid X)$ be the propensity score for treatment. It is known in randomized studies. However, it needs to be estimated in observational studies. We may posit model a parametric model $\pi(X; \gamma)$,such as the logistic regression model, and estimate $\gamma$ via the maximum likelihood estimator $\widehat{\gamma}$. The estimator (2) is consistent for $E\{Y^*(g_{\eta}\}$ only $\pi(X; \gamma)$, and hence $\pi_c(X;\eta, \gamma)$, is correctly specified. We find the maximizer of $\text{IWPE}(\eta)$, and denoted it by $\widehat{\eta}^{opt}$. Hence, an estimator for the optimal regime $\widehat{g}_{\eta}^{opt}(X) = g(X, \widehat{\eta}^{opt})$. A corresponding estimator the $E\{ Y^*(g_{\eta}^{opt})\}$ is $\text{IPWE}(\widehat{\eta}^{opt})$.

To be protected against mis-specification and improve efficiency, a doubly robust Augmented Inverse Probability Weighted Estimator (AIPWE) is proposed by adopting both estimators above and formalized as
$$AIPWE(\eta) = n^{-1} \sum_{i=1}^n\left\{ \frac{C_{\eta,i} Y_i}{\pi_{c}(X_i; \eta, \widehat{\gamma})} - \frac{C_{\eta,i} - \pi_c(X_i; \eta, \widehat{\gamma})}{\pi_c(X_i;\eta, \widehat{\gamma})}m(X_i;\eta,\widehat{\beta})\right\}$$
where $m(X_i;\eta,\beta) = Q(X, 1, \beta) g(X, \eta) + Q(X, 0, \beta)\{1 - g(X,\eta)\}$ is a model for $E\{ Y^*(g_{\eta})\mid X\} = Q(X, 1) g (X, \eta) + Q(X, 0) \{ 1 - g(X, \eta)\}$. As mentioned in the outcome regression part, $Q(X, a, \beta)$ is a model for $E(Y \mid A, X)$,  and $\widehat{\beta}$ is an appropriate estimator for $\beta$. Again, we find a maximizer of $\text{AIPWE}(\eta)$, denoted by $\widehat{\eta}^{opt}$. Hence, we obtain the estimators $\widehat{g}_{\eta}^{opt}(X) = g(X, \widehat{\eta}^{opt})$ and $\text{AIPWE}(\widehat{\eta}^{opt})$.


